{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6e4403a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "063db0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv(\"/Users/kwonheejin/Documents/DL/dataset/HAR/UCI HAR Dataset/features.txt\", sep='\\s+', header=None, names=['column_index', 'column_name'])\n",
    "features_cc = features.groupby('column_name').cumcount()\n",
    "features_cc = pd.DataFrame(features_cc)\n",
    "features_cc.columns = ['cumcount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89aade8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = pd.read_csv(\"/Users/kwonheejin/Documents/DL/dataset/HAR/UCI HAR Dataset/features.txt\", sep='\\s+', header=None, names=['column_index', 'column_name'])\n",
    "\n",
    "# 피쳐이름에 그룹바이와 cumcount를 적용한 데이터프레임을 만든다\n",
    "features_cc = features_df.groupby('column_name').cumcount() # (561, )의 시리즈 생성됨\n",
    "features_cc = pd.DataFrame(features_cc) # (561, 1)의 데이터프레임으로 변환\n",
    "features_cc.columns = ['cumcount'] # 칼럼명 추가\n",
    "features_cc = features_cc.reset_index() # (561,2)가 된다.\n",
    "features_df = features_df.reset_index() # (561,3)이 된다.\n",
    "\n",
    "# 양쪽 데이터프레임 reset_index()의 결과로 생긴 'index'열을 기준으로 outer join(병합)한다.\n",
    "# 그럼 결과적으로 index, column_index, column_name, cumcount 4개의 열을 가진 데이터프레임이 생성된다.\n",
    "new_df = pd.merge(features_cc, features_df, on='index', how='outer')\n",
    "\n",
    "# 병합에 사용되었던 index 칼럼을 드랍한다.\n",
    "new_df = new_df.drop(['index'], axis=1) # column_index, column_name, cumcount의 (561,3)이 된다.\n",
    "\n",
    "# column_name과 cumcount를 합쳐서 하나의 column_name으로 만드는 과정이다\n",
    "# cumcount가 1이상일경우 column_name 뒤에 _1 또는 _2를 붙인다.\n",
    "new_df['column_name'] = new_df[['column_name', 'cumcount']].apply(lambda x: x[0]+'_'+str(x[1])\n",
    "                                                                if x[1]>0 else x[0], axis=1)\n",
    "\n",
    "# cumcount를 column_name을 새로짓는 데 사용하였으므로 이제 드랍한다.\n",
    "# 이 작업을 마치면 cumcount 칼럼이 없어져서 (561,2) 데이터프레임이 된다.\n",
    "new_df = new_df.drop(['cumcount'], axis=1) # column_index, column_name 두개의 (561,2) 가 된다.\n",
    "\n",
    "h = new_df['column_name'].value_counts()\n",
    "\n",
    "for i in h:\n",
    "    if (i == 3):\n",
    "        print(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8fd9239c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7352, 561), (2947, 561), (7352, 1), (2947, 1))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = pd.read_csv(\"/Users/kwonheejin/Documents/DL/dataset/HAR/UCI HAR Dataset/train/X_train.txt\", header=None, sep=\"\\s+\", names=new_df['column_name'].values)\n",
    "y_train = pd.read_csv(\"/Users/kwonheejin/Documents/DL/dataset/HAR/UCI HAR Dataset/train/y_train.txt\", header=None, sep=\"\\s+\", names=['activity'])\n",
    "X_test = pd.read_csv(\"/Users/kwonheejin/Documents/DL/dataset/HAR/UCI HAR Dataset/test/X_test.txt\", header=None, sep=\"\\s+\", names=new_df['column_name'].values)\n",
    "y_test = pd.read_csv(\"/Users/kwonheejin/Documents/DL/dataset/HAR/UCI HAR Dataset/test/y_test.txt\", header=None, sep=\"\\s+\", names=['activity'])\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f53419da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7352, 562), (2947, 562))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "scaled_X_train = pd.DataFrame(data=X_train, columns=new_df['column_name'].values)\n",
    "scaled_X_test = pd.DataFrame(data=X_test, columns=new_df['column_name'].values)\n",
    "scaled_X_train['label'] = y_train.values\n",
    "scaled_X_test['label'] = y_test.values\n",
    "\n",
    "scaled_X_train.shape, scaled_X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14d2e35c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4067, 562), (3285, 562), (1560, 562), (1387, 562), (7352, 562), (2947, 562))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_static = scaled_X_train[scaled_X_train['label'] > 3]\n",
    "X_train_dynamic = scaled_X_train[scaled_X_train['label'] <= 3]\n",
    "X_test_static = scaled_X_test[scaled_X_test['label'] > 3]\n",
    "X_test_dynamic = scaled_X_test[scaled_X_test['label'] <= 3]\n",
    "\n",
    "X_train_combined = scaled_X_train\n",
    "X_test_combined = scaled_X_test\n",
    "\n",
    "X_train_static.shape, X_train_dynamic.shape, X_test_static.shape, X_test_dynamic.shape, X_train_combined.shape, X_test_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0fe7462",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_static = X_train_static['label']\n",
    "y_train_dynamic = X_train_dynamic['label']\n",
    "y_train_combined = X_train_combined['label']\n",
    "y_test_static = X_test_static['label']\n",
    "y_test_dynamic = X_test_dynamic['label']\n",
    "y_test_combined = X_test_combined['label']\n",
    "\n",
    "X_train_static = X_train_static.drop('label', axis=1)\n",
    "X_train_dynamic = X_train_dynamic.drop('label', axis=1)\n",
    "X_train_combined = X_train_combined.drop('label', axis=1)\n",
    "X_test_static = X_test_static.drop('label', axis=1)\n",
    "X_test_dynamic = X_test_dynamic.drop('label', axis=1)\n",
    "X_test_combined = X_test_combined.drop('label', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4645782",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4067, 561), (1560, 561), (3285, 561), (1387, 561), (7352, 561), (2947, 561))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_static.shape, X_test_static.shape, X_train_dynamic.shape, X_test_dynamic.shape, X_train_combined.shape, X_test_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca737608",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "def create_dataset(X, y, time_steps=1, step=1):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(0, len(X) - time_steps, step):\n",
    "        v = X.iloc[i:(i + time_steps)].values\n",
    "        labels = y.iloc[i: i + time_steps]\n",
    "        Xs.append(v)        \n",
    "        ys.append(stats.mode(labels)[0][0])\n",
    "    return np.array(Xs), np.array(ys).reshape(-1, 1)\n",
    "\n",
    "TIME_STEPS = 10\n",
    "STEP = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9ab075d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_y/cmlp5dyd3tdb35r5_kr1z35w0000gn/T/ipykernel_9717/1253865503.py:9: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  ys.append(stats.mode(labels)[0][0])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((4057, 10, 561), (4057, 1))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_static, y_train_static = create_dataset(X_train_static, y_train_static, TIME_STEPS, STEP)\n",
    "X_train_dynamic, y_train_dynamic = create_dataset(X_train_dynamic, y_train_dynamic, TIME_STEPS, STEP)\n",
    "X_train_combined, y_train_combined = create_dataset(X_train_combined, y_train_combined, TIME_STEPS, STEP)\n",
    "X_test_static, y_test_static = create_dataset(X_test_static, y_test_static, TIME_STEPS, STEP)\n",
    "X_test_dynamic, y_test_dynamic = create_dataset(X_test_dynamic, y_test_dynamic, TIME_STEPS, STEP)\n",
    "X_test_combined, y_test_combined = create_dataset(X_test_combined, y_test_combined, TIME_STEPS, STEP)\n",
    "\n",
    "X_train_static.shape, y_train_static.shape,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1e83726",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kwonheejin/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/Users/kwonheejin/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/Users/kwonheejin/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "enc_static = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "enc_static = enc_static.fit(y_train_static)\n",
    "\n",
    "enc_dynamic = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "enc_dynamic = enc_dynamic.fit(y_train_dynamic)\n",
    "\n",
    "enc_combined = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "enc_combined = enc_combined.fit(y_train_combined)\n",
    "\n",
    "y_train_static = enc_static.transform(y_train_static)\n",
    "y_test_static = enc_static.transform(y_test_static)\n",
    "\n",
    "y_train_dynamic = enc_dynamic.transform(y_train_dynamic)\n",
    "y_test_dynamic = enc_dynamic.transform(y_test_dynamic)\n",
    "\n",
    "y_train_combined = enc_combined.transform(y_train_combined)\n",
    "y_test_combined = enc_combined.transform(y_test_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8edc3f48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3275, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_dynamic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "19923723",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "\n",
    "def model_CNN(X_train_mod, y_train_mod):\n",
    "    model = Sequential([\n",
    "        Conv1D(32, kernel_size=3, activation='relu', input_shape=(X_train_mod.shape[1], X_train_mod.shape[2])),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(y_train_mod.shape[1], activation='softmax')\n",
    "    ])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "86d6946e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_2 (Conv1D)           (None, 8, 32)             53888     \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPoolin  (None, 4, 32)             0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 70787 (276.51 KB)\n",
      "Trainable params: 70787 (276.51 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_static = model_CNN(X_train_static, y_train_static)\n",
    "model_static.summary()\n",
    "\n",
    "model_static.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ac87080c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_4 (Conv1D)           (None, 8, 32)             53888     \n",
      "                                                                 \n",
      " max_pooling1d_4 (MaxPoolin  (None, 4, 32)             0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 70787 (276.51 KB)\n",
      "Trainable params: 70787 (276.51 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_dynamic = model_CNN(X_train_dynamic, y_train_dynamic)\n",
    "model_dynamic.summary()\n",
    "\n",
    "model_dynamic.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1565b765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_5 (Conv1D)           (None, 8, 32)             53888     \n",
      "                                                                 \n",
      " max_pooling1d_5 (MaxPoolin  (None, 4, 32)             0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 71174 (278.02 KB)\n",
      "Trainable params: 71174 (278.02 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_combined = model_CNN(X_train_combined, y_train_combined)\n",
    "model_combined.summary()\n",
    "\n",
    "model_combined.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "06d57a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 1.7579e-04 - acc: 1.0000 - val_loss: 0.3464 - val_acc: 0.9557\n",
      "Epoch 2/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 5.9680e-06 - acc: 1.0000 - val_loss: 0.3467 - val_acc: 0.9557\n",
      "Epoch 3/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 7.1611e-04 - acc: 0.9996 - val_loss: 0.6206 - val_acc: 0.9401\n",
      "Epoch 4/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.0119 - acc: 0.9961 - val_loss: 0.3492 - val_acc: 0.9557\n",
      "Epoch 5/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 6.8797e-06 - acc: 1.0000 - val_loss: 0.3272 - val_acc: 0.9532\n",
      "Epoch 6/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 7.8688e-05 - acc: 1.0000 - val_loss: 0.3239 - val_acc: 0.9540\n",
      "Epoch 7/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 2.0748e-05 - acc: 1.0000 - val_loss: 0.3248 - val_acc: 0.9540\n",
      "Epoch 8/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 4.4857e-06 - acc: 1.0000 - val_loss: 0.3226 - val_acc: 0.9557\n",
      "Epoch 9/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 3.3932e-05 - acc: 1.0000 - val_loss: 0.3348 - val_acc: 0.9532\n",
      "Epoch 10/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 7.1528e-07 - acc: 1.0000 - val_loss: 0.3371 - val_acc: 0.9532\n",
      "Epoch 11/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 2.5305e-06 - acc: 1.0000 - val_loss: 0.3370 - val_acc: 0.9532\n",
      "Epoch 12/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 6.8336e-07 - acc: 1.0000 - val_loss: 0.3367 - val_acc: 0.9532\n",
      "Epoch 13/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 5.2549e-06 - acc: 1.0000 - val_loss: 0.3360 - val_acc: 0.9540\n",
      "Epoch 14/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 1.3874e-04 - acc: 1.0000 - val_loss: 0.3739 - val_acc: 0.9557\n",
      "Epoch 15/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 1.2176e-05 - acc: 1.0000 - val_loss: 0.3609 - val_acc: 0.9548\n",
      "Epoch 16/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 1.2832e-06 - acc: 1.0000 - val_loss: 0.3569 - val_acc: 0.9557\n",
      "Epoch 17/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 1.4192e-06 - acc: 1.0000 - val_loss: 0.3555 - val_acc: 0.9557\n",
      "Epoch 18/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 1.1828e-06 - acc: 1.0000 - val_loss: 0.3552 - val_acc: 0.9557\n",
      "Epoch 19/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 3.9042e-05 - acc: 1.0000 - val_loss: 0.3387 - val_acc: 0.9581\n",
      "Epoch 20/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 2.0640e-05 - acc: 1.0000 - val_loss: 0.3022 - val_acc: 0.9581\n",
      "Epoch 21/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 3.2600e-06 - acc: 1.0000 - val_loss: 0.3007 - val_acc: 0.9598\n",
      "Epoch 22/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 3.3527e-06 - acc: 1.0000 - val_loss: 0.3004 - val_acc: 0.9598\n",
      "Epoch 23/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 1.1730e-06 - acc: 1.0000 - val_loss: 0.3010 - val_acc: 0.9598\n",
      "Epoch 24/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 6.0986e-07 - acc: 1.0000 - val_loss: 0.3010 - val_acc: 0.9598\n",
      "Epoch 25/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 4.8995e-07 - acc: 1.0000 - val_loss: 0.3011 - val_acc: 0.9598\n",
      "Epoch 26/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 4.0182e-07 - acc: 1.0000 - val_loss: 0.3014 - val_acc: 0.9598\n",
      "Epoch 27/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 5.2710e-07 - acc: 1.0000 - val_loss: 0.3021 - val_acc: 0.9598\n",
      "Epoch 28/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 1.2620e-06 - acc: 1.0000 - val_loss: 0.3029 - val_acc: 0.9598\n",
      "Epoch 29/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 1.5984e-06 - acc: 1.0000 - val_loss: 0.3028 - val_acc: 0.9598\n",
      "Epoch 30/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 6.7122e-06 - acc: 1.0000 - val_loss: 0.3060 - val_acc: 0.9598\n",
      "Epoch 31/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 5.7160e-06 - acc: 1.0000 - val_loss: 0.3154 - val_acc: 0.9581\n",
      "Epoch 32/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 6.1309e-07 - acc: 1.0000 - val_loss: 0.3149 - val_acc: 0.9581\n",
      "Epoch 33/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 5.0392e-06 - acc: 1.0000 - val_loss: 0.3154 - val_acc: 0.9581\n",
      "Epoch 34/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 1.0468e-07 - acc: 1.0000 - val_loss: 0.3156 - val_acc: 0.9581\n",
      "Epoch 35/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 5.3729e-07 - acc: 1.0000 - val_loss: 0.3156 - val_acc: 0.9581\n",
      "Epoch 36/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 3.1363e-06 - acc: 1.0000 - val_loss: 0.3179 - val_acc: 0.9581\n",
      "Epoch 37/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 1.3781e-06 - acc: 1.0000 - val_loss: 0.3189 - val_acc: 0.9581\n",
      "Epoch 38/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 2.8702e-06 - acc: 1.0000 - val_loss: 0.3158 - val_acc: 0.9581\n",
      "Epoch 39/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 1.3600e-06 - acc: 1.0000 - val_loss: 0.3170 - val_acc: 0.9598\n",
      "Epoch 40/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 4.2243e-07 - acc: 1.0000 - val_loss: 0.3171 - val_acc: 0.9598\n",
      "Epoch 41/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 1.8777e-07 - acc: 1.0000 - val_loss: 0.3168 - val_acc: 0.9598\n",
      "Epoch 42/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 5.7753e-07 - acc: 1.0000 - val_loss: 0.3178 - val_acc: 0.9589\n",
      "Epoch 43/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 2.0457e-07 - acc: 1.0000 - val_loss: 0.3181 - val_acc: 0.9589\n",
      "Epoch 44/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 2.1534e-07 - acc: 1.0000 - val_loss: 0.3182 - val_acc: 0.9589\n",
      "Epoch 45/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 1.7553e-06 - acc: 1.0000 - val_loss: 0.3208 - val_acc: 0.9581\n",
      "Epoch 46/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 1.5019e-07 - acc: 1.0000 - val_loss: 0.3214 - val_acc: 0.9581\n",
      "Epoch 47/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 1.0274e-06 - acc: 1.0000 - val_loss: 0.3213 - val_acc: 0.9589\n",
      "Epoch 48/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 1.2124e-06 - acc: 1.0000 - val_loss: 0.3212 - val_acc: 0.9598\n",
      "Epoch 49/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 9.7751e-08 - acc: 1.0000 - val_loss: 0.3214 - val_acc: 0.9598\n",
      "Epoch 50/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 9.8147e-07 - acc: 1.0000 - val_loss: 0.3221 - val_acc: 0.9598\n",
      "Epoch 51/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 2.9553e-06 - acc: 1.0000 - val_loss: 0.3240 - val_acc: 0.9589\n",
      "Epoch 52/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 2.8576e-07 - acc: 1.0000 - val_loss: 0.3249 - val_acc: 0.9598\n",
      "Epoch 53/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 2.1950e-06 - acc: 1.0000 - val_loss: 0.3219 - val_acc: 0.9598\n",
      "Epoch 54/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 6.4164e-07 - acc: 1.0000 - val_loss: 0.3233 - val_acc: 0.9598\n",
      "Epoch 55/100\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 1.5603e-07 - acc: 1.0000 - val_loss: 0.3236 - val_acc: 0.9598\n",
      "Epoch 56/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 2.7681e-07 - acc: 1.0000 - val_loss: 0.3237 - val_acc: 0.9598\n",
      "Epoch 57/100\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 5.3358e-07 - acc: 1.0000 - val_loss: 0.3262 - val_acc: 0.9589\n",
      "Epoch 58/100\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 3.3832e-07 - acc: 1.0000 - val_loss: 0.3263 - val_acc: 0.9589\n",
      "Epoch 59/100\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 1.4331e-06 - acc: 1.0000 - val_loss: 0.3220 - val_acc: 0.9598\n",
      "Epoch 60/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 5.7638e-07 - acc: 1.0000 - val_loss: 0.3230 - val_acc: 0.9589\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 3ms/step - loss: 0.0049 - acc: 0.9986 - val_loss: 0.7153 - val_acc: 0.9302\n",
      "Epoch 62/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.0704 - acc: 0.9908 - val_loss: 1.9363 - val_acc: 0.8801\n",
      "Epoch 63/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.0309 - acc: 0.9947 - val_loss: 0.3616 - val_acc: 0.9573\n",
      "Epoch 64/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 4.8697e-04 - acc: 0.9996 - val_loss: 0.2421 - val_acc: 0.9631\n",
      "Epoch 65/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 3.3784e-05 - acc: 1.0000 - val_loss: 0.2541 - val_acc: 0.9614\n",
      "Epoch 66/100\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 3.5779e-06 - acc: 1.0000 - val_loss: 0.2554 - val_acc: 0.9614\n",
      "Epoch 67/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 2.3222e-05 - acc: 1.0000 - val_loss: 0.2676 - val_acc: 0.9606\n",
      "Epoch 68/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 5.0570e-05 - acc: 1.0000 - val_loss: 0.2901 - val_acc: 0.9614\n",
      "Epoch 69/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 9.6360e-06 - acc: 1.0000 - val_loss: 0.2864 - val_acc: 0.9606\n",
      "Epoch 70/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 7.7542e-06 - acc: 1.0000 - val_loss: 0.2852 - val_acc: 0.9614\n",
      "Epoch 71/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 4.1735e-06 - acc: 1.0000 - val_loss: 0.2845 - val_acc: 0.9614\n",
      "Epoch 72/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 1.4629e-06 - acc: 1.0000 - val_loss: 0.2850 - val_acc: 0.9614\n",
      "Epoch 73/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 1.5370e-06 - acc: 1.0000 - val_loss: 0.2849 - val_acc: 0.9614\n",
      "Epoch 74/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 1.9637e-05 - acc: 1.0000 - val_loss: 0.2961 - val_acc: 0.9606\n",
      "Epoch 75/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 9.6737e-04 - acc: 0.9993 - val_loss: 0.3946 - val_acc: 0.9573\n",
      "Epoch 76/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 3.3856e-05 - acc: 1.0000 - val_loss: 0.3622 - val_acc: 0.9548\n",
      "Epoch 77/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 2.3671e-05 - acc: 1.0000 - val_loss: 0.3569 - val_acc: 0.9557\n",
      "Epoch 78/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 9.4922e-07 - acc: 1.0000 - val_loss: 0.3520 - val_acc: 0.9557\n",
      "Epoch 79/100\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 2.3557e-06 - acc: 1.0000 - val_loss: 0.3525 - val_acc: 0.9557\n",
      "Epoch 80/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 1.2531e-05 - acc: 1.0000 - val_loss: 0.3532 - val_acc: 0.9565\n",
      "Epoch 81/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 2.2949e-04 - acc: 1.0000 - val_loss: 0.5026 - val_acc: 0.9516\n",
      "Epoch 82/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 5.5326e-05 - acc: 1.0000 - val_loss: 0.4790 - val_acc: 0.9499\n",
      "Epoch 83/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 7.9275e-06 - acc: 1.0000 - val_loss: 0.4772 - val_acc: 0.9483\n",
      "Epoch 84/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 2.3517e-07 - acc: 1.0000 - val_loss: 0.4772 - val_acc: 0.9483\n",
      "Epoch 85/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 1.1179e-05 - acc: 1.0000 - val_loss: 0.4727 - val_acc: 0.9499\n",
      "Epoch 86/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 6.4957e-08 - acc: 1.0000 - val_loss: 0.4726 - val_acc: 0.9499\n",
      "Epoch 87/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 8.9525e-07 - acc: 1.0000 - val_loss: 0.4721 - val_acc: 0.9499\n",
      "Epoch 88/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 7.3067e-06 - acc: 1.0000 - val_loss: 0.4685 - val_acc: 0.9499\n",
      "Epoch 89/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 8.6414e-04 - acc: 0.9996 - val_loss: 0.4534 - val_acc: 0.9540\n",
      "Epoch 90/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.0010 - acc: 0.9996 - val_loss: 0.5671 - val_acc: 0.9442\n",
      "Epoch 91/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 1.1264e-05 - acc: 1.0000 - val_loss: 0.5500 - val_acc: 0.9442\n",
      "Epoch 92/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 5.5728e-05 - acc: 1.0000 - val_loss: 0.5409 - val_acc: 0.9475\n",
      "Epoch 93/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 9.2554e-07 - acc: 1.0000 - val_loss: 0.5383 - val_acc: 0.9483\n",
      "Epoch 94/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 7.3313e-05 - acc: 1.0000 - val_loss: 0.4982 - val_acc: 0.9524\n",
      "Epoch 95/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 1.4741e-05 - acc: 1.0000 - val_loss: 0.4822 - val_acc: 0.9507\n",
      "Epoch 96/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 7.9512e-07 - acc: 1.0000 - val_loss: 0.4794 - val_acc: 0.9516\n",
      "Epoch 97/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 2.2465e-07 - acc: 1.0000 - val_loss: 0.4796 - val_acc: 0.9516\n",
      "Epoch 98/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 2.3531e-06 - acc: 1.0000 - val_loss: 0.4795 - val_acc: 0.9516\n",
      "Epoch 99/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 4.9165e-07 - acc: 1.0000 - val_loss: 0.4798 - val_acc: 0.9516\n",
      "Epoch 100/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 8.8009e-08 - acc: 1.0000 - val_loss: 0.4798 - val_acc: 0.9516\n"
     ]
    }
   ],
   "source": [
    "history_static = model_static.fit(X_train_static, y_train_static, epochs=100, batch_size=32, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "99f064ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "72/72 [==============================] - 1s 3ms/step - loss: 0.4029 - acc: 0.8434 - val_loss: 0.2049 - val_acc: 0.9217\n",
      "Epoch 2/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1321 - acc: 0.9520 - val_loss: 0.1829 - val_acc: 0.9278\n",
      "Epoch 3/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.0530 - acc: 0.9808 - val_loss: 0.2565 - val_acc: 0.9318\n",
      "Epoch 4/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.0382 - acc: 0.9860 - val_loss: 0.1401 - val_acc: 0.9471\n",
      "Epoch 5/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.0540 - acc: 0.9847 - val_loss: 0.1525 - val_acc: 0.9471\n",
      "Epoch 6/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.0300 - acc: 0.9921 - val_loss: 0.1780 - val_acc: 0.9502\n",
      "Epoch 7/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.0106 - acc: 0.9965 - val_loss: 0.2698 - val_acc: 0.9471\n",
      "Epoch 8/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.0097 - acc: 0.9965 - val_loss: 0.2925 - val_acc: 0.9440\n",
      "Epoch 9/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.0057 - acc: 0.9983 - val_loss: 0.1477 - val_acc: 0.9583\n",
      "Epoch 10/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.0067 - acc: 0.9978 - val_loss: 0.1512 - val_acc: 0.9563\n",
      "Epoch 11/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.0061 - acc: 0.9983 - val_loss: 0.1655 - val_acc: 0.9522\n",
      "Epoch 12/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.0124 - acc: 0.9969 - val_loss: 0.1124 - val_acc: 0.9634\n",
      "Epoch 13/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.0078 - acc: 0.9974 - val_loss: 0.1702 - val_acc: 0.9542\n",
      "Epoch 14/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.1871 - val_acc: 0.9552\n",
      "Epoch 15/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.0020 - acc: 0.9991 - val_loss: 0.2542 - val_acc: 0.9491\n",
      "Epoch 16/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.2784 - val_acc: 0.9522\n",
      "Epoch 17/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 5.3109e-04 - acc: 1.0000 - val_loss: 0.2765 - val_acc: 0.9481\n",
      "Epoch 18/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 5.4516e-04 - acc: 1.0000 - val_loss: 0.2664 - val_acc: 0.9512\n",
      "Epoch 19/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 3.1646e-04 - acc: 1.0000 - val_loss: 0.2630 - val_acc: 0.9502\n",
      "Epoch 20/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.0496 - acc: 0.9817 - val_loss: 0.2447 - val_acc: 0.9410\n",
      "Epoch 21/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.0176 - acc: 0.9943 - val_loss: 0.2022 - val_acc: 0.9583\n",
      "Epoch 22/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.0113 - acc: 0.9969 - val_loss: 0.3608 - val_acc: 0.9420\n",
      "Epoch 23/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.0139 - acc: 0.9965 - val_loss: 0.0830 - val_acc: 0.9746\n",
      "Epoch 24/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.0236 - acc: 0.9913 - val_loss: 0.0675 - val_acc: 0.9736\n",
      "Epoch 25/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.0078 - acc: 0.9983 - val_loss: 0.2115 - val_acc: 0.9563\n",
      "Epoch 26/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.0041 - acc: 0.9974 - val_loss: 0.0963 - val_acc: 0.9736\n",
      "Epoch 27/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 7.9313e-04 - acc: 1.0000 - val_loss: 0.1391 - val_acc: 0.9654\n",
      "Epoch 28/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 3.6805e-04 - acc: 1.0000 - val_loss: 0.1822 - val_acc: 0.9603\n",
      "Epoch 29/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.0027 - acc: 0.9991 - val_loss: 0.1559 - val_acc: 0.9674\n",
      "Epoch 30/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.2155 - val_acc: 0.9603\n",
      "Epoch 31/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 3.7191e-04 - acc: 1.0000 - val_loss: 0.1585 - val_acc: 0.9674\n",
      "Epoch 32/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.0023 - acc: 0.9991 - val_loss: 0.0783 - val_acc: 0.9797\n",
      "Epoch 33/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.0389 - acc: 0.9895 - val_loss: 0.2633 - val_acc: 0.9440\n",
      "Epoch 34/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.0145 - acc: 0.9943 - val_loss: 0.2888 - val_acc: 0.9552\n",
      "Epoch 35/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.0023 - acc: 0.9991 - val_loss: 0.1281 - val_acc: 0.9715\n",
      "Epoch 36/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.0069 - acc: 0.9983 - val_loss: 0.0383 - val_acc: 0.9898\n",
      "Epoch 37/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.0047 - acc: 0.9983 - val_loss: 0.1251 - val_acc: 0.9705\n",
      "Epoch 38/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 7.1043e-04 - acc: 1.0000 - val_loss: 0.1409 - val_acc: 0.9725\n",
      "Epoch 39/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 6.0976e-04 - acc: 0.9996 - val_loss: 0.2034 - val_acc: 0.9613\n",
      "Epoch 40/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.0014 - acc: 0.9991 - val_loss: 0.1641 - val_acc: 0.9654\n",
      "Epoch 41/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.7722e-04 - acc: 1.0000 - val_loss: 0.1222 - val_acc: 0.9725\n",
      "Epoch 42/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.2982e-04 - acc: 1.0000 - val_loss: 0.1246 - val_acc: 0.9736\n",
      "Epoch 43/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.3822e-04 - acc: 1.0000 - val_loss: 0.1259 - val_acc: 0.9746\n",
      "Epoch 44/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 8.3841e-05 - acc: 1.0000 - val_loss: 0.1272 - val_acc: 0.9746\n",
      "Epoch 45/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.1783e-04 - acc: 1.0000 - val_loss: 0.1202 - val_acc: 0.9736\n",
      "Epoch 46/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 7.9851e-05 - acc: 1.0000 - val_loss: 0.1156 - val_acc: 0.9797\n",
      "Epoch 47/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 3.9221e-05 - acc: 1.0000 - val_loss: 0.1161 - val_acc: 0.9797\n",
      "Epoch 48/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 8.1405e-05 - acc: 1.0000 - val_loss: 0.1020 - val_acc: 0.9807\n",
      "Epoch 49/100\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 1.0531e-04 - acc: 1.0000 - val_loss: 0.1064 - val_acc: 0.9797\n",
      "Epoch 50/100\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 1.4595e-04 - acc: 1.0000 - val_loss: 0.1151 - val_acc: 0.9807\n",
      "Epoch 51/100\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 5.1342e-05 - acc: 1.0000 - val_loss: 0.1254 - val_acc: 0.9766\n",
      "Epoch 52/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 2.7135e-05 - acc: 1.0000 - val_loss: 0.1318 - val_acc: 0.9746\n",
      "Epoch 53/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 5.8994e-05 - acc: 1.0000 - val_loss: 0.1257 - val_acc: 0.9766\n",
      "Epoch 54/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 5.3091e-05 - acc: 1.0000 - val_loss: 0.1251 - val_acc: 0.9746\n",
      "Epoch 55/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.4062e-04 - acc: 1.0000 - val_loss: 0.1384 - val_acc: 0.9715\n",
      "Epoch 56/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 5.6747e-05 - acc: 1.0000 - val_loss: 0.1761 - val_acc: 0.9654\n",
      "Epoch 57/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 2.2811e-05 - acc: 1.0000 - val_loss: 0.1540 - val_acc: 0.9674\n",
      "Epoch 58/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 9.5782e-05 - acc: 1.0000 - val_loss: 0.1262 - val_acc: 0.9715\n",
      "Epoch 59/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 3.0571e-05 - acc: 1.0000 - val_loss: 0.1267 - val_acc: 0.9736\n",
      "Epoch 60/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 2.9824e-05 - acc: 1.0000 - val_loss: 0.1294 - val_acc: 0.9746\n",
      "Epoch 61/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.5714e-05 - acc: 1.0000 - val_loss: 0.1344 - val_acc: 0.9725\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 0s 3ms/step - loss: 2.2382e-05 - acc: 1.0000 - val_loss: 0.1257 - val_acc: 0.9756\n",
      "Epoch 63/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 2.4956e-05 - acc: 1.0000 - val_loss: 0.1355 - val_acc: 0.9725\n",
      "Epoch 64/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 3.1915e-05 - acc: 1.0000 - val_loss: 0.1424 - val_acc: 0.9736\n",
      "Epoch 65/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 8.9911e-06 - acc: 1.0000 - val_loss: 0.1426 - val_acc: 0.9725\n",
      "Epoch 66/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.2916e-04 - acc: 1.0000 - val_loss: 0.0822 - val_acc: 0.9807\n",
      "Epoch 67/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.0462 - acc: 0.9917 - val_loss: 0.4616 - val_acc: 0.9461\n",
      "Epoch 68/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.0250 - acc: 0.9926 - val_loss: 0.3963 - val_acc: 0.9532\n",
      "Epoch 69/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.0043 - acc: 0.9991 - val_loss: 0.4303 - val_acc: 0.9532\n",
      "Epoch 70/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 3.0629e-04 - acc: 1.0000 - val_loss: 0.5333 - val_acc: 0.9552\n",
      "Epoch 71/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 3.0670e-04 - acc: 1.0000 - val_loss: 0.4659 - val_acc: 0.9563\n",
      "Epoch 72/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.0689e-04 - acc: 1.0000 - val_loss: 0.4697 - val_acc: 0.9563\n",
      "Epoch 73/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.0072 - acc: 0.9969 - val_loss: 0.2176 - val_acc: 0.9563\n",
      "Epoch 74/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.0147 - acc: 0.9956 - val_loss: 0.1641 - val_acc: 0.9685\n",
      "Epoch 75/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.0039 - acc: 0.9996 - val_loss: 0.2728 - val_acc: 0.9573\n",
      "Epoch 76/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.0035 - acc: 0.9983 - val_loss: 0.1581 - val_acc: 0.9715\n",
      "Epoch 77/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.0030 - acc: 0.9991 - val_loss: 0.2393 - val_acc: 0.9593\n",
      "Epoch 78/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.0054 - acc: 0.9983 - val_loss: 0.5469 - val_acc: 0.9440\n",
      "Epoch 79/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.0110 - acc: 0.9974 - val_loss: 0.1382 - val_acc: 0.9685\n",
      "Epoch 80/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 9.4766e-04 - acc: 0.9991 - val_loss: 0.1856 - val_acc: 0.9695\n",
      "Epoch 81/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.3699e-04 - acc: 1.0000 - val_loss: 0.1866 - val_acc: 0.9705\n",
      "Epoch 82/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.5507e-04 - acc: 1.0000 - val_loss: 0.2503 - val_acc: 0.9634\n",
      "Epoch 83/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.0028 - acc: 0.9987 - val_loss: 0.3223 - val_acc: 0.9563\n",
      "Epoch 84/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.9408e-04 - acc: 1.0000 - val_loss: 0.2450 - val_acc: 0.9624\n",
      "Epoch 85/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 2.1764e-04 - acc: 1.0000 - val_loss: 0.2306 - val_acc: 0.9603\n",
      "Epoch 86/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 7.9369e-05 - acc: 1.0000 - val_loss: 0.2320 - val_acc: 0.9624\n",
      "Epoch 87/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 6.7345e-04 - acc: 0.9996 - val_loss: 0.2876 - val_acc: 0.9613\n",
      "Epoch 88/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 4.3692e-04 - acc: 0.9996 - val_loss: 0.2153 - val_acc: 0.9664\n",
      "Epoch 89/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.0038 - acc: 0.9983 - val_loss: 0.0855 - val_acc: 0.9786\n",
      "Epoch 90/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 3.0301e-04 - acc: 1.0000 - val_loss: 0.2305 - val_acc: 0.9664\n",
      "Epoch 91/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.0017 - acc: 0.9991 - val_loss: 0.4274 - val_acc: 0.9542\n",
      "Epoch 92/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.0042 - acc: 0.9996 - val_loss: 0.0884 - val_acc: 0.9847\n",
      "Epoch 93/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 3.3821e-04 - acc: 1.0000 - val_loss: 0.0925 - val_acc: 0.9837\n",
      "Epoch 94/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 3.1663e-04 - acc: 1.0000 - val_loss: 0.0802 - val_acc: 0.9858\n",
      "Epoch 95/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.2606e-04 - acc: 1.0000 - val_loss: 0.0931 - val_acc: 0.9868\n",
      "Epoch 96/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 2.5296e-04 - acc: 1.0000 - val_loss: 0.1122 - val_acc: 0.9817\n",
      "Epoch 97/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 5.7468e-05 - acc: 1.0000 - val_loss: 0.0993 - val_acc: 0.9837\n",
      "Epoch 98/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 2.3707e-05 - acc: 1.0000 - val_loss: 0.0908 - val_acc: 0.9847\n",
      "Epoch 99/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 2.0035e-05 - acc: 1.0000 - val_loss: 0.0947 - val_acc: 0.9837\n",
      "Epoch 100/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 2.2391e-06 - acc: 1.0000 - val_loss: 0.0970 - val_acc: 0.9837\n"
     ]
    }
   ],
   "source": [
    "history_dynamic = model_dynamic.fit(X_train_dynamic, y_train_dynamic, epochs=100, batch_size=32, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "25d9bfbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "161/161 [==============================] - 1s 3ms/step - loss: 0.5016 - acc: 0.8186 - val_loss: 0.2550 - val_acc: 0.9119\n",
      "Epoch 2/100\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.1048 - acc: 0.9628 - val_loss: 0.2958 - val_acc: 0.9242\n",
      "Epoch 3/100\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.0522 - acc: 0.9803 - val_loss: 0.2666 - val_acc: 0.9319\n",
      "Epoch 4/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 0.0478 - acc: 0.9852 - val_loss: 0.3422 - val_acc: 0.9251\n",
      "Epoch 5/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 0.0329 - acc: 0.9868 - val_loss: 0.3524 - val_acc: 0.9237\n",
      "Epoch 6/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 0.0325 - acc: 0.9866 - val_loss: 0.2330 - val_acc: 0.9510\n",
      "Epoch 7/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 0.0079 - acc: 0.9979 - val_loss: 0.2438 - val_acc: 0.9469\n",
      "Epoch 8/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 0.0140 - acc: 0.9961 - val_loss: 0.2765 - val_acc: 0.9419\n",
      "Epoch 9/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 0.0113 - acc: 0.9959 - val_loss: 0.2527 - val_acc: 0.9478\n",
      "Epoch 10/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 0.0197 - acc: 0.9944 - val_loss: 0.2368 - val_acc: 0.9455\n",
      "Epoch 11/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 0.0184 - acc: 0.9957 - val_loss: 0.3292 - val_acc: 0.9405\n",
      "Epoch 12/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 0.0202 - acc: 0.9942 - val_loss: 0.3999 - val_acc: 0.9378\n",
      "Epoch 13/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 0.0153 - acc: 0.9951 - val_loss: 0.3807 - val_acc: 0.9378\n",
      "Epoch 14/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 0.0288 - acc: 0.9928 - val_loss: 0.3093 - val_acc: 0.9324\n",
      "Epoch 15/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 0.0101 - acc: 0.9973 - val_loss: 0.2116 - val_acc: 0.9532\n",
      "Epoch 16/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 0.0054 - acc: 0.9988 - val_loss: 0.2789 - val_acc: 0.9469\n",
      "Epoch 17/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 0.0601 - acc: 0.9862 - val_loss: 0.4944 - val_acc: 0.9378\n",
      "Epoch 18/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 0.0098 - acc: 0.9967 - val_loss: 0.4530 - val_acc: 0.9419\n",
      "Epoch 19/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 0.0017 - acc: 0.9992 - val_loss: 0.3835 - val_acc: 0.9414\n",
      "Epoch 20/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 0.0031 - acc: 0.9994 - val_loss: 0.3715 - val_acc: 0.9455\n",
      "Epoch 21/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 0.0051 - acc: 0.9981 - val_loss: 0.2195 - val_acc: 0.9578\n",
      "Epoch 22/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 0.0085 - acc: 0.9975 - val_loss: 0.4347 - val_acc: 0.9424\n",
      "Epoch 23/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 0.0145 - acc: 0.9957 - val_loss: 0.3756 - val_acc: 0.9405\n",
      "Epoch 24/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 0.0239 - acc: 0.9938 - val_loss: 0.5521 - val_acc: 0.9387\n",
      "Epoch 25/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 0.0199 - acc: 0.9961 - val_loss: 0.3706 - val_acc: 0.9473\n",
      "Epoch 26/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 0.0129 - acc: 0.9967 - val_loss: 0.4492 - val_acc: 0.9433\n",
      "Epoch 27/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 0.0444 - acc: 0.9903 - val_loss: 0.3089 - val_acc: 0.9492\n",
      "Epoch 28/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 0.0165 - acc: 0.9961 - val_loss: 0.4544 - val_acc: 0.9428\n",
      "Epoch 29/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 0.0024 - acc: 0.9990 - val_loss: 0.3913 - val_acc: 0.9483\n",
      "Epoch 30/100\n",
      "161/161 [==============================] - 1s 3ms/step - loss: 0.0021 - acc: 0.9992 - val_loss: 0.4495 - val_acc: 0.9483\n",
      "Epoch 31/100\n",
      "161/161 [==============================] - 1s 3ms/step - loss: 1.6219e-04 - acc: 1.0000 - val_loss: 0.5011 - val_acc: 0.9469\n",
      "Epoch 32/100\n",
      "161/161 [==============================] - 1s 3ms/step - loss: 2.4616e-04 - acc: 1.0000 - val_loss: 0.5495 - val_acc: 0.9464\n",
      "Epoch 33/100\n",
      "161/161 [==============================] - 1s 4ms/step - loss: 4.4468e-04 - acc: 0.9998 - val_loss: 0.5348 - val_acc: 0.9492\n",
      "Epoch 34/100\n",
      "161/161 [==============================] - 1s 4ms/step - loss: 0.0237 - acc: 0.9949 - val_loss: 0.5795 - val_acc: 0.9378\n",
      "Epoch 35/100\n",
      "161/161 [==============================] - 1s 4ms/step - loss: 0.0612 - acc: 0.9854 - val_loss: 0.3272 - val_acc: 0.9455\n",
      "Epoch 36/100\n",
      "161/161 [==============================] - 1s 3ms/step - loss: 0.0138 - acc: 0.9969 - val_loss: 0.5537 - val_acc: 0.9478\n",
      "Epoch 37/100\n",
      "161/161 [==============================] - 1s 4ms/step - loss: 0.0053 - acc: 0.9982 - val_loss: 0.7197 - val_acc: 0.9396\n",
      "Epoch 38/100\n",
      "161/161 [==============================] - 1s 4ms/step - loss: 0.0014 - acc: 0.9992 - val_loss: 0.6988 - val_acc: 0.9346\n",
      "Epoch 39/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 0.0184 - acc: 0.9973 - val_loss: 0.5839 - val_acc: 0.9433\n",
      "Epoch 40/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 9.4435e-04 - acc: 0.9996 - val_loss: 0.5501 - val_acc: 0.9473\n",
      "Epoch 41/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 0.0298 - acc: 0.9953 - val_loss: 0.4004 - val_acc: 0.9523\n",
      "Epoch 42/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 0.0592 - acc: 0.9899 - val_loss: 0.6092 - val_acc: 0.9451\n",
      "Epoch 43/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 0.0149 - acc: 0.9965 - val_loss: 0.3682 - val_acc: 0.9655\n",
      "Epoch 44/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 0.0043 - acc: 0.9994 - val_loss: 0.4342 - val_acc: 0.9582\n",
      "Epoch 45/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 7.1563e-04 - acc: 0.9998 - val_loss: 0.4294 - val_acc: 0.9591\n",
      "Epoch 46/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 0.0011 - acc: 0.9996 - val_loss: 0.5264 - val_acc: 0.9542\n",
      "Epoch 47/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 0.0028 - acc: 0.9990 - val_loss: 0.6451 - val_acc: 0.9532\n",
      "Epoch 48/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 0.0120 - acc: 0.9975 - val_loss: 0.5362 - val_acc: 0.9523\n",
      "Epoch 49/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 6.2538e-04 - acc: 0.9996 - val_loss: 0.6366 - val_acc: 0.9505\n",
      "Epoch 50/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 2.1278e-05 - acc: 1.0000 - val_loss: 0.6340 - val_acc: 0.9510\n",
      "Epoch 51/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 0.0021 - acc: 0.9996 - val_loss: 1.4440 - val_acc: 0.9110\n",
      "Epoch 52/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 0.0658 - acc: 0.9901 - val_loss: 0.8910 - val_acc: 0.9428\n",
      "Epoch 53/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 0.0248 - acc: 0.9961 - val_loss: 0.5735 - val_acc: 0.9560\n",
      "Epoch 54/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 0.0022 - acc: 0.9994 - val_loss: 0.4139 - val_acc: 0.9569\n",
      "Epoch 55/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 0.0046 - acc: 0.9992 - val_loss: 0.4050 - val_acc: 0.9564\n",
      "Epoch 56/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 0.0054 - acc: 0.9990 - val_loss: 0.6100 - val_acc: 0.9542\n",
      "Epoch 57/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 0.0085 - acc: 0.9992 - val_loss: 0.3620 - val_acc: 0.9610\n",
      "Epoch 58/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 0.0308 - acc: 0.9951 - val_loss: 0.4847 - val_acc: 0.9537\n",
      "Epoch 59/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 0.0180 - acc: 0.9961 - val_loss: 0.9847 - val_acc: 0.9351\n",
      "Epoch 60/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 0.0083 - acc: 0.9977 - val_loss: 0.9312 - val_acc: 0.9492\n",
      "Epoch 61/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 0.0296 - acc: 0.9965 - val_loss: 0.8314 - val_acc: 0.9437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 0.0075 - acc: 0.9981 - val_loss: 0.7130 - val_acc: 0.9523\n",
      "Epoch 63/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 0.0088 - acc: 0.9992 - val_loss: 0.6215 - val_acc: 0.9560\n",
      "Epoch 64/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 8.3476e-06 - acc: 1.0000 - val_loss: 0.6023 - val_acc: 0.9560\n",
      "Epoch 65/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 0.0035 - acc: 0.9996 - val_loss: 0.6032 - val_acc: 0.9555\n",
      "Epoch 66/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 0.0093 - acc: 0.9973 - val_loss: 1.1998 - val_acc: 0.9192\n",
      "Epoch 67/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 0.0263 - acc: 0.9955 - val_loss: 0.7207 - val_acc: 0.9442\n",
      "Epoch 68/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 0.0126 - acc: 0.9975 - val_loss: 0.4930 - val_acc: 0.9523\n",
      "Epoch 69/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 0.0140 - acc: 0.9979 - val_loss: 0.9227 - val_acc: 0.9492\n",
      "Epoch 70/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 0.0087 - acc: 0.9990 - val_loss: 0.5775 - val_acc: 0.9523\n",
      "Epoch 71/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 4.9119e-04 - acc: 1.0000 - val_loss: 0.4692 - val_acc: 0.9637\n",
      "Epoch 72/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 0.0063 - acc: 0.9981 - val_loss: 0.4126 - val_acc: 0.9605\n",
      "Epoch 73/100\n",
      "161/161 [==============================] - 1s 3ms/step - loss: 0.0145 - acc: 0.9963 - val_loss: 0.6291 - val_acc: 0.9483\n",
      "Epoch 74/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 0.0068 - acc: 0.9986 - val_loss: 0.5437 - val_acc: 0.9532\n",
      "Epoch 75/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 0.0086 - acc: 0.9994 - val_loss: 0.5602 - val_acc: 0.9560\n",
      "Epoch 76/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 3.8649e-04 - acc: 0.9998 - val_loss: 0.4772 - val_acc: 0.9564\n",
      "Epoch 77/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 0.0022 - acc: 0.9994 - val_loss: 0.4450 - val_acc: 0.9582\n",
      "Epoch 78/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 0.0106 - acc: 0.9975 - val_loss: 0.5202 - val_acc: 0.9532\n",
      "Epoch 79/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 0.0061 - acc: 0.9988 - val_loss: 0.7112 - val_acc: 0.9487\n",
      "Epoch 80/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 0.0105 - acc: 0.9973 - val_loss: 0.9647 - val_acc: 0.9383\n",
      "Epoch 81/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 0.0156 - acc: 0.9981 - val_loss: 1.0534 - val_acc: 0.9419\n",
      "Epoch 82/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 0.0068 - acc: 0.9986 - val_loss: 0.8848 - val_acc: 0.9510\n",
      "Epoch 83/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 0.0011 - acc: 0.9998 - val_loss: 0.7771 - val_acc: 0.9560\n",
      "Epoch 84/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 0.0023 - acc: 0.9994 - val_loss: 1.0091 - val_acc: 0.9546\n",
      "Epoch 85/100\n",
      "161/161 [==============================] - 1s 3ms/step - loss: 0.0300 - acc: 0.9971 - val_loss: 1.1833 - val_acc: 0.9410\n",
      "Epoch 86/100\n",
      "161/161 [==============================] - 1s 3ms/step - loss: 0.0155 - acc: 0.9975 - val_loss: 1.0524 - val_acc: 0.9383\n",
      "Epoch 87/100\n",
      "161/161 [==============================] - 1s 3ms/step - loss: 0.0094 - acc: 0.9982 - val_loss: 1.0948 - val_acc: 0.9396\n",
      "Epoch 88/100\n",
      "161/161 [==============================] - 1s 3ms/step - loss: 0.0145 - acc: 0.9981 - val_loss: 1.1550 - val_acc: 0.9464\n",
      "Epoch 89/100\n",
      "161/161 [==============================] - 1s 3ms/step - loss: 0.0481 - acc: 0.9957 - val_loss: 0.5755 - val_acc: 0.9519\n",
      "Epoch 90/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 0.0259 - acc: 0.9957 - val_loss: 0.5593 - val_acc: 0.9519\n",
      "Epoch 91/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 6.6387e-04 - acc: 0.9996 - val_loss: 0.6148 - val_acc: 0.9573\n",
      "Epoch 92/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 0.0157 - acc: 0.9981 - val_loss: 0.4101 - val_acc: 0.9601\n",
      "Epoch 93/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 9.1039e-04 - acc: 0.9998 - val_loss: 0.5569 - val_acc: 0.9601\n",
      "Epoch 94/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 0.0030 - acc: 0.9996 - val_loss: 0.3902 - val_acc: 0.9655\n",
      "Epoch 95/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 0.0025 - acc: 0.9998 - val_loss: 0.4865 - val_acc: 0.9637\n",
      "Epoch 96/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 0.0059 - acc: 0.9990 - val_loss: 0.6636 - val_acc: 0.9555\n",
      "Epoch 97/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 2.5717e-04 - acc: 0.9998 - val_loss: 0.5224 - val_acc: 0.9614\n",
      "Epoch 98/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 2.9693e-04 - acc: 0.9998 - val_loss: 0.5999 - val_acc: 0.9591\n",
      "Epoch 99/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 0.0030 - acc: 0.9994 - val_loss: 0.5294 - val_acc: 0.9573\n",
      "Epoch 100/100\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 1.6789e-05 - acc: 1.0000 - val_loss: 0.5330 - val_acc: 0.9573\n"
     ]
    }
   ],
   "source": [
    "history_combined = model_combined.fit(X_train_combined, y_train_combined, epochs=100, batch_size=32, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d04b967",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
